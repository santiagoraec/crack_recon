{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e26332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.ndimage import convolve\n",
    "from skimage.filters import frangi, sato, threshold_otsu\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk, skeletonize, binary_dilation, reconstruction\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2485095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def turn_grey(image):\n",
    "    \"\"\"\n",
    "    Turns the input image to greyscale\n",
    "    \n",
    "    :param image: image to be turned gray\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def to_uint8(binary):\n",
    "    return binary.astype(np.uint8) * 255\n",
    "\n",
    "def resize_image(image, scale_percent):\n",
    "    \"\"\"\n",
    "    Scales input image using a percentage\n",
    "    \n",
    "    :param image: Input image\n",
    "    :param scale_percent: ratio to which the image is being resized\n",
    "    \"\"\"\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    new_width = int(width * scale_percent / 100)\n",
    "    new_height = int(height * scale_percent / 100)\n",
    "    rezised_image = cv2.resize(image, (new_width, new_height))\n",
    "    return rezised_image\n",
    "\n",
    "def resize_image_to_side(image, side_length):\n",
    "    \"\"\"\n",
    "    Resizes input image to desired side length \n",
    "    \n",
    "    :param image: Input image to be resized\n",
    "    :param side_length: Desired side length\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    if width >= height:\n",
    "        scale_percent = (side_length / width) * 100\n",
    "    else:\n",
    "        scale_percent = (side_length / height) * 100\n",
    "    return resize_image(image, scale_percent)\n",
    "\n",
    "def mild_smooth(img, method=\"gaussian\", ksize=3, sigma=1.0):\n",
    "    \n",
    "    if method == \"gaussian\":\n",
    "        return cv2.GaussianBlur(img, (ksize, ksize), sigma)\n",
    "    \n",
    "    elif method == \"median\":\n",
    "        return cv2.medianBlur(img, ksize)\n",
    "    \n",
    "    elif method == \"bilateral\":\n",
    "        # Diameter = ksize, sigmaColor = sigma, sigmaSpace = sigma\n",
    "        return cv2.bilateralFilter(img, d=ksize, sigmaColor=sigma*25, sigmaSpace=sigma*25)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'gaussian', 'median', or 'bilateral'.\")\n",
    "    \n",
    "def apply_clahe(img):\n",
    "    \"\"\"\n",
    "    Applies clahe with pre-tested fairly well working parameters to enhance contrast\n",
    "    \n",
    "    :param img: Image to be boosted in contrast\n",
    "    \"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img)\n",
    "\n",
    "def apply_frangi(img):\n",
    "    \"\"\"\n",
    "    Tries to recognize vessel like structures using frangi\n",
    "    \n",
    "    :param img: Image to be vesselized \n",
    "    \"\"\"\n",
    "    # skimage expects float in [0,1]\n",
    "    img_norm = img.astype(np.float32) / 255.0\n",
    "    return frangi(img_norm,\n",
    "                    scale_range=(1, 2),\n",
    "                #   scale_step=2,\n",
    "                #   beta=0.5,\n",
    "                #   alpha=0.5,\n",
    "                #   gamma=15,\n",
    "                    black_ridges=True\n",
    "                  )\n",
    "\n",
    "def _order_points_clockwise(pts):\n",
    "    \"\"\"\n",
    "    Order 4 points consistently: top-left, top-right, bottom-right, bottom-left.\n",
    "    Input: pts as numpy array shape (4,2) (float or int).\n",
    "    \"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]      # top-left has smallest sum (x+y)\n",
    "    rect[2] = pts[np.argmax(s)]      # bottom-right has largest sum\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]   # top-right has smallest (x-y)\n",
    "    rect[3] = pts[np.argmax(diff)]   # bottom-left has largest (x-y)\n",
    "    return rect\n",
    "\n",
    "def normalize(img):\n",
    "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "def extract_square_glass_bmp(image_or_path,\n",
    "                             output_path=None,\n",
    "                             margin=0,\n",
    "                             min_area_ratio=0.001,\n",
    "                             debug=False):\n",
    "    \"\"\"\n",
    "    Detect the largest square/rectangular sample in the input (preserving original resolution),\n",
    "    deskew it and return (and optionally save) a square BMP image of the sample.\n",
    "\n",
    "    Parameters:\n",
    "    - image_or_path: numpy array (grayscale or BGR) OR path string to image file.\n",
    "    - output_path: if provided, save the result as BMP at this path; if None, do not save.\n",
    "    - margin: additional pixels to add around the detected square in the output (keeps resolution).\n",
    "    - min_area_ratio: ignore tiny contours smaller than this fraction of image area.\n",
    "    - debug: if True, returns a tuple (warped, debug_vis) where debug_vis draws the detected box.\n",
    "\n",
    "    Returns:\n",
    "    - warped (numpy uint8 image) or (warped, debug_vis) if debug=True.\n",
    "    Notes:\n",
    "    - The output size equals the detected side length (in original pixels) + 2*margin -> no resampling down/up.\n",
    "    - If detection fails, the original image is returned (and saved if output_path provided).\n",
    "    \"\"\"\n",
    "\n",
    "    # Load if path string given\n",
    "    if isinstance(image_or_path, (str,)):\n",
    "        img = cv2.imread(image_or_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Could not load image: {image_or_path}\")\n",
    "    else:\n",
    "        img = image_or_path.copy()\n",
    "\n",
    "    # Keep original for return/save\n",
    "    orig = img.copy()\n",
    "\n",
    "    # Ensure grayscale for edge detection\n",
    "    if orig.ndim == 3:\n",
    "        gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = orig\n",
    "\n",
    "    h, w = gray.shape[:2]\n",
    "    image_area = float(w * h)\n",
    "\n",
    "    # Preprocess: slight blur to reduce noise, then edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # Use automatic Canny thresholds based on median (robust to exposure)\n",
    "    med = np.median(blurred)\n",
    "    lower = int(max(0, 0.66 * med))\n",
    "    upper = int(min(255, 1.33 * med))\n",
    "    edges = cv2.Canny(blurred, lower, upper)\n",
    "\n",
    "    # Close small gaps on the border lines (helps faint borders)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Find external contours\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        # nothing found -> return original (optionally save)\n",
    "        if output_path:\n",
    "            cv2.imwrite(output_path, orig)\n",
    "        if debug:\n",
    "            debug_vis = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "            return orig, debug_vis\n",
    "        return orig\n",
    "\n",
    "    # Filter and pick the best contour: largest by area above threshold\n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < image_area * min_area_ratio:\n",
    "            continue\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        candidates.append((area, approx, c))\n",
    "\n",
    "    if not candidates:\n",
    "        # fallback to largest contour without area filter\n",
    "        largest = max(contours, key=cv2.contourArea)\n",
    "        rect = cv2.minAreaRect(largest)\n",
    "        box = cv2.boxPoints(rect)\n",
    "    else:\n",
    "        # prefer a 4-vertex polygon with largest area\n",
    "        candidates.sort(key=lambda x: (x[0], -len(x[1])), reverse=True)\n",
    "        best_area, best_approx, best_contour = candidates[0]\n",
    "        if best_approx.shape[0] == 4:\n",
    "            box = best_approx.reshape(4,2).astype(\"float32\")\n",
    "        else:\n",
    "            rect = cv2.minAreaRect(best_contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "\n",
    "    box = np.asarray(box, dtype=\"float32\")\n",
    "    rect = _order_points_clockwise(box)\n",
    "\n",
    "    # Compute side length (use the maximum of widths/heights to obtain a square)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.linalg.norm(br - bl)\n",
    "    widthB = np.linalg.norm(tr - tl)\n",
    "    heightA = np.linalg.norm(tr - br)\n",
    "    heightB = np.linalg.norm(tl - bl)\n",
    "    maxSide = int(max(widthA, widthB, heightA, heightB))\n",
    "\n",
    "    if maxSide <= 0:\n",
    "        # Something went wrong; return original\n",
    "        if output_path:\n",
    "            cv2.imwrite(output_path, orig)\n",
    "        if debug:\n",
    "            debug_vis = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "            return orig, debug_vis\n",
    "        return orig\n",
    "\n",
    "    # - - - replace the perspective warp below with the rotation-based crop - - -\n",
    "    # Use the detected box to compute a robust rotated rect (center, size, angle)\n",
    "    rect_rot = cv2.minAreaRect(box)  # ((cx,cy),(w,h),angle)\n",
    "    (cx, cy), (rw, rh), angle = rect_rot\n",
    "\n",
    "    # OpenCV returns angle such that width may be the shorter side; ensure we rotate so longer side is horizontal\n",
    "    if rw < rh:\n",
    "        angle += 90.0\n",
    "        rw, rh = rh, rw\n",
    "\n",
    "    # Build rotation matrix around full-image center of rectangle and rotate full-res image (no scaling)\n",
    "    center = (float(cx), float(cy))\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(orig, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # Transform detected box points into rotated image coordinates and crop tight bounding box\n",
    "    box_pts = cv2.transform(np.array([box]), M)[0]\n",
    "    x_min = max(0, int(np.floor(box_pts[:, 0].min())) - margin)\n",
    "    x_max = min(rotated.shape[1], int(np.ceil(box_pts[:, 0].max())) + margin)\n",
    "    y_min = max(0, int(np.floor(box_pts[:, 1].min())) - margin)\n",
    "    y_max = min(rotated.shape[0], int(np.ceil(box_pts[:, 1].max())) + margin)\n",
    "\n",
    "    cropped = rotated[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Pad to exact square without resampling (centered)\n",
    "    ch, cw = cropped.shape[:2]\n",
    "    side = max(ch, cw)\n",
    "    top = (side - ch) // 2\n",
    "    bottom = side - ch - top\n",
    "    left = (side - cw) // 2\n",
    "    right = side - cw - left\n",
    "    final = cv2.copyMakeBorder(cropped, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Ensure uint8 (BMP requires 8-bit channels)\n",
    "    if final.dtype != np.uint8:\n",
    "        final = normalize(final).astype(np.uint8)\n",
    "\n",
    "    # Save if requested (BMP format)\n",
    "    if output_path:\n",
    "        out_path = str(output_path)\n",
    "        if not out_path.lower().endswith(\".bmp\"):\n",
    "            out_path = out_path + \".bmp\"\n",
    "        cv2.imwrite(out_path, final)\n",
    "\n",
    "    if debug:\n",
    "        debug_vis = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        int_box = box.astype(int)\n",
    "        cv2.polylines(debug_vis, [int_box.reshape(-1,1,2)], True, (0,255,0), 3)\n",
    "        return final, debug_vis\n",
    "\n",
    "    return cv2.rotate(final, cv2.ROTATE_90_CLOCKWISE)  # rotate 90 degree clockwise to get original orientation\n",
    "\n",
    "def clean_edges(binary, margin = 40):\n",
    "    \"\"\"\n",
    "    Cleans all elements from the edges of a binary mask following a margin\n",
    "    \n",
    "    :param binary: binary mask to be cleaned\n",
    "    :param margin: how much should it be removed\n",
    "    \"\"\"\n",
    "    h, w = binary.shape  \n",
    "\n",
    "    # Create a mask that’s True everywhere except near the border\n",
    "    mask = np.zeros_like(binary, dtype=bool)\n",
    "    mask[margin:h - margin, margin:w - margin] = True\n",
    "\n",
    "    # Keep only central detections\n",
    "    return binary & mask\n",
    "\n",
    "def generate_mask(img):\n",
    "    \"\"\"\n",
    "    Pipeline to generate a binary mask of ruptures from image using sato instead of frangi.\n",
    "    The last step cleans too many pixels away and thus is not very good\n",
    "    \n",
    "    :param img: Image to be pipelined\n",
    "    \"\"\"\n",
    "    # Contrast Enhancement\n",
    "    clahe_img = apply_clahe(img)\n",
    "    # to float32\n",
    "    img = clahe_img.astype(np.float32) / 255.0\n",
    "    # Sato threshholding\n",
    "    v_sato = sato(img, sigmas=range(1, 8), black_ridges=True)\n",
    "    # Otsu autothesholding\n",
    "    thresh = threshold_otsu(v_sato)\n",
    "    binary = v_sato > thresh\n",
    "    # Morphological cleaning\n",
    "    binary = remove_small_objects(binary, 100)\n",
    "    binary = binary_closing(binary, disk(2))\n",
    "\n",
    "    labeled = label(binary)\n",
    "    filtered = np.zeros_like(binary)\n",
    "\n",
    "    for region in regionprops(labeled):\n",
    "        # region.eccentricity ∈ [0,1], close to 1 = elongated (cracks)\n",
    "        # region.solidity close to 1 = solid blob (bubbles)\n",
    "        if region.eccentricity > 0.9 and region.solidity < 0.95:\n",
    "            filtered[labeled == region.label] = 1\n",
    "\n",
    "    return filtered.astype(bool)\n",
    "\n",
    "\n",
    "# Generate mask without the last step of filtering by region properties\n",
    "def generate_mask_incomplete(img):\n",
    "    \"\"\"\n",
    "    Another pipeline to generate a mask, without one step of cleaning which was taking off too many elements\n",
    "    \n",
    "    :param img: Description\n",
    "    \"\"\"\n",
    "\n",
    "    # Contrast Enhancement\n",
    "    clahe_img = apply_clahe(img)\n",
    "    # to float32\n",
    "    img = clahe_img.astype(np.float32) / 255.0\n",
    "    # Sato threshholding\n",
    "    v_sato = sato(img, sigmas=range(1, 8), black_ridges=True)\n",
    "    # Otsu autothesholding\n",
    "    thresh = threshold_otsu(v_sato)\n",
    "    binary = v_sato > thresh\n",
    "    # Morphological cleaning\n",
    "    binary = remove_small_objects(binary, 100)\n",
    "    binary = binary_closing(binary, disk(2))\n",
    "\n",
    "    return binary.astype(bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a22939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refined pipelines\n",
    "def generate_mask_trans(img):\n",
    "    \"\"\"\n",
    "    Transmission channel pipeline.\n",
    "    Very conservative, used mostly as veto/support.\n",
    "    \"\"\"\n",
    "\n",
    "    clahe_img = apply_clahe(img)\n",
    "    img = clahe_img.astype(np.float32) / 255.0\n",
    "\n",
    "    v_sato = sato(\n",
    "        img,\n",
    "        sigmas=range(3, 12),\n",
    "        black_ridges=False  # IMPORTANT\n",
    "    )\n",
    "\n",
    "    v_sato /= (v_sato.max() + 1e-8)\n",
    "\n",
    "    # Transmission benefits from higher threshold\n",
    "    thresh = threshold_otsu(v_sato)\n",
    "    binary = v_sato > thresh * 1.2\n",
    "\n",
    "    binary = remove_small_objects(binary, 200)\n",
    "    binary = binary_closing(binary, disk(3))\n",
    "\n",
    "    return binary.astype(bool), v_sato\n",
    "\n",
    "def generate_mask_blue(img):\n",
    "    \"\"\"\n",
    "    Blue channel: PRIMARY detector\n",
    "    \"\"\"\n",
    "\n",
    "    clahe_img = apply_clahe(img)\n",
    "    img = clahe_img.astype(np.float32) / 255.0\n",
    "\n",
    "    v_sato = sato(\n",
    "        img,\n",
    "        sigmas=range(1, 8),\n",
    "        black_ridges=True\n",
    "    )\n",
    "\n",
    "    v_sato /= (v_sato.max() + 1e-8)\n",
    "\n",
    "    thresh = threshold_otsu(v_sato)\n",
    "    binary = v_sato > thresh\n",
    "\n",
    "    binary = remove_small_objects(binary, 100)\n",
    "    binary = binary_closing(binary, disk(2))\n",
    "\n",
    "    return binary.astype(bool), v_sato\n",
    "\n",
    "def generate_mask_green(img):\n",
    "    \"\"\"\n",
    "    Green channel pipeline.\n",
    "    Used as a SUPPORT signal, not a primary detector.\n",
    "    \"\"\"\n",
    "\n",
    "    clahe_img = apply_clahe(img)\n",
    "    img = clahe_img.astype(np.float32) / 255.0\n",
    "\n",
    "    # Slightly larger scales, green tends to show thicker features\n",
    "    v_sato = sato(\n",
    "        img,\n",
    "        sigmas=range(2, 10),\n",
    "        black_ridges=True\n",
    "    )\n",
    "\n",
    "    # Normalize for later fusion\n",
    "    v_sato /= (v_sato.max() + 1e-8)\n",
    "\n",
    "    thresh = threshold_otsu(v_sato)\n",
    "    binary = v_sato > thresh * 1.1  # be stricter than blue\n",
    "\n",
    "    binary = remove_small_objects(binary, 150)\n",
    "    binary = binary_closing(binary, disk(2))\n",
    "\n",
    "    return binary.astype(bool), v_sato\n",
    "\n",
    "def combine_three(img_green, img_blue, img_trans):\n",
    "    \"\"\"\n",
    "    Combines three channels in a physically meaningful way.\n",
    "    Blue dominates geometry, others add confidence.\n",
    "    \"\"\"\n",
    "\n",
    "    _, v_blue  = generate_mask_blue(img_blue)\n",
    "    _, v_green = generate_mask_green(img_green)\n",
    "    _, v_trans = generate_mask_trans(img_trans)\n",
    "\n",
    "    # Weighted fusion (blue-dominant)\n",
    "    v_fused = (\n",
    "        0.6 * v_blue +\n",
    "        0.25 * v_green +\n",
    "        0.15 * v_trans\n",
    "    )\n",
    "\n",
    "    thresh = threshold_otsu(v_fused)\n",
    "    binary = v_fused > thresh\n",
    "\n",
    "    binary = remove_small_objects(binary, 120)\n",
    "    binary = binary_closing(binary, disk(2))\n",
    "\n",
    "    return binary.astype(bool), v_fused\n",
    "\n",
    "def combine_three_strict(img_green, img_blue, img_trans):\n",
    "    \"\"\"\n",
    "    Blue = detector\n",
    "    Green + transmission = confidence veto\n",
    "    \"\"\"\n",
    "\n",
    "    mask_blue, v_blue   = generate_mask_blue(img_blue)\n",
    "    _, v_green          = generate_mask_green(img_green)\n",
    "    _, v_trans          = generate_mask_trans(img_trans)\n",
    "\n",
    "    confidence = (\n",
    "        v_green +\n",
    "        v_trans\n",
    "    )\n",
    "\n",
    "    confidence /= (confidence.max() + 1e-8)\n",
    "\n",
    "    final = mask_blue & (confidence > 0.3)\n",
    "\n",
    "    final = remove_small_objects(final, 120)\n",
    "    final = binary_closing(final, disk(2))\n",
    "\n",
    "    return final.astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_blue = extract_square_glass_bmp(\"input_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedBlue].bmp\")\n",
    "img_green = extract_square_glass_bmp(\"input_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedGreen].bmp\")\n",
    "img_trans = extract_square_glass_bmp(\"input_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [Transmission].bmp\")\n",
    "resized_img_blue = resize_image_to_side(img_blue, 1500)\n",
    "resized_img_green = resize_image_to_side(img_green, 1500)\n",
    "resized_img_trans = resize_image_to_side(img_trans, 1500)\n",
    "\n",
    "#combined_binary, combined_sato = combine_three(resized_img_green, resized_img_blue, resized_img_trans)\n",
    "combined_binary_strict = combine_three_strict(resized_img_green, resized_img_blue, resized_img_trans)\n",
    "#cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [Combined].bmp\", to_uint8(combined_binary))\n",
    "cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [Combined_Strict].bmp\", to_uint8(combined_binary_strict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9665eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_cracks_from_origin(gray_uint8,\n",
    "                               origin=None,\n",
    "                               low_thr=10,          # very low: preserves faint lines\n",
    "                               bridge_radius=1,     # small dilation to bridge gaps\n",
    "                               seed_radius=4,       # seed disk at the origin\n",
    "                               max_seed_radius=160, # grow if seed doesn’t touch lines\n",
    "                               min_obj=20):\n",
    "    \"\"\"\n",
    "    gray_uint8: grayscale image (0..255) where cracks are light on dark.\n",
    "    origin: (y, x). If None, auto-estimate by densest neighborhood.\n",
    "    Returns boolean mask of crack network connected to origin.\n",
    "    \"\"\"\n",
    "    # 1) Gentle binarization (invert if needed so cracks are True and sparse)\n",
    "    binary = gray_uint8 >= low_thr\n",
    "    if binary.mean() > 0.5:\n",
    "        binary = ~binary\n",
    "\n",
    "    binary = remove_small_objects(binary, min_obj)\n",
    "\n",
    "    # 2) Auto origin near densest junction if not given\n",
    "    if origin is None:\n",
    "        neigh = convolve(binary.astype(np.uint8), np.ones((3,3), np.uint8))\n",
    "        origin = np.unravel_index(np.argmax(neigh), neigh.shape)\n",
    "\n",
    "    # 3) Bridge tiny gaps\n",
    "    bridged = binary_dilation(binary, disk(bridge_radius))\n",
    "\n",
    "    # 4) Geodesic reconstruction (region growing from origin *inside* the crack mask)\n",
    "    def grow(mask, origin, r0, rmax):\n",
    "        for r in range(r0, rmax+1, 2):\n",
    "            seed = np.zeros_like(mask, np.uint8)\n",
    "            cv2.circle(seed, (int(origin[1]), int(origin[0])), r, 1, -1)\n",
    "            seed = (seed > 0) & mask                  # must be <= mask for reconstruction\n",
    "            if seed.any():\n",
    "                recon = reconstruction(seed.astype(float), mask.astype(float),\n",
    "                                       method='dilation') > 0\n",
    "                if recon.any():\n",
    "                    return recon, r\n",
    "        return np.zeros_like(mask, bool), None\n",
    "\n",
    "    recon, used_r = grow(bridged, origin, seed_radius, max_seed_radius)\n",
    "    return recon, origin, used_r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936bd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Processing BrightPolarizedBlue Scan\n",
    "img_blue = extract_square_glass_bmp(\"input_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedBlue].bmp\")\n",
    "resized_img_blue = resize_image_to_side(img_blue, 1500)\n",
    "img_blue_complete = to_uint8(generate_mask(resized_img_blue))\n",
    "img_blue_incomplete = to_uint8(generate_mask_incomplete(resized_img_blue))\n",
    "cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedBlue][Complete].bmp\", img_blue_complete)\n",
    "cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedBlue][Incomplete].bmp\", img_blue_incomplete)\n",
    "\n",
    "#Processing BrightPolarizedGreen Scan\n",
    "img_green = extract_square_glass_bmp(\"input_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedGreen].bmp\")\n",
    "resized_img_green = resize_image_to_side(img_green, 1500)\n",
    "img_green_complete = to_uint8(generate_mask(resized_img_green))\n",
    "img_green_incomplete = to_uint8(generate_mask(resized_img_green))\n",
    "cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedGreen][Complete].bmp\", img_green_complete)\n",
    "cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedGreen][Incomplete].bmp\", img_green_incomplete)\n",
    "\n",
    "#Processing Transmission Scan\n",
    "img_trans = extract_square_glass_bmp(\"input_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [Transmission].bmp\")\n",
    "resized_img_trans = resize_image_to_side(img_trans, 1500)\n",
    "img_trans_complete = to_uint8(generate_mask(resized_img_trans))\n",
    "img_trans_incomplete = to_uint8(generate_mask(resized_img_trans))\n",
    "cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [Transmission][Complete].bmp\", img_trans_complete)\n",
    "cv2.imwrite(\"output_samples/0940 2024-07-29 14h17 pre (0,212-4915,7571) [Transmission][Incomplete].bmp\", img_trans_incomplete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1378a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing area\n",
    "\n",
    "# img = extract_square_glass_bmp(\"Proben/4.70.B.01/fracture/morphology/0940 2024-07-29 14h17 pre (0,212-4915,7571) [BrightPolarizedBlue].bmp\",\n",
    "#                                  margin=2, debug=False)\n",
    "\n",
    "# cv2.imwrite(\"out/extracted_square.png\", img)\n",
    "\n",
    "# img = img.astype(np.float32) / 255.0\n",
    "\n",
    "# v_sato = sato(img, sigmas=range(1, 8), black_ridges=True)\n",
    "# v_frangi = frangi(img, sigmas=range(1, 8), black_ridges=True)\n",
    "\n",
    "# cv2.imwrite(\"out/sato_output.png\", normalize((v_sato * 255).astype(np.uint8)))\n",
    "# cv2.imwrite(\"out/frangi_output.png\", normalize((v_frangi * 255).astype(np.uint8)))\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(v_sato, cmap='gray')\n",
    "# plt.title('Sato')\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(v_frangi, cmap='gray')\n",
    "# plt.title('Frangi')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
